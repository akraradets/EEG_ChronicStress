{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pandas as pd\n",
    "import mne\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(scores):\n",
    "    scores = np.array(scores)\n",
    "    lower_threshold = scores.mean() - (scores.std()/2)\n",
    "    upper_threshold = scores.mean() + (scores.std()/2)\n",
    "    return scores.mean(), (lower_threshold,upper_threshold)\n",
    "\n",
    "def get_stress_type(score, grade):\n",
    "    \"\"\" Non-stress (0): score < lower_threshold\n",
    "        Neutral    (1): lower_threshold <= score <= upper_threshold\n",
    "        Stress     (2): score > lower_threshold \"\"\"\n",
    "    if(score < grade[0]):\n",
    "        return 0\n",
    "    elif(score <= grade[1]):\n",
    "        return 1\n",
    "    elif(score > grade[1]):\n",
    "        return 2\n",
    "\n",
    "def PSS_printer(PSS):\n",
    "    # peak at info\n",
    "    temp = PSS.popitem()\n",
    "    PSS[temp[0]] = temp[1]\n",
    "    column = list(temp[1].keys())\n",
    "    space = \"\\t\\t\"\n",
    "    print(f\"Name{space}\",f\"{space}\".join(column),sep=\"\" )\n",
    "    print(\"=\"*60)\n",
    "    for name, info in PSS.items():\n",
    "        print(f\"{name}{space}\",sep=\"\",end=\"\")\n",
    "        for col in column:\n",
    "            print(f\"{info[col]}{space}\",end=\"\")\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "TYPE_DEF = {0:'Non-Stress', 1:'Neutral', 2: 'Stress'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSS = dict()\n",
    "scores = []\n",
    "with open('./PSS_scores.csv','r') as f:\n",
    "    f.readline() # skip header\n",
    "    for line in f.readlines(): \n",
    "        name,score = line.split(',')\n",
    "        PSS[name] = {'score':int(score)}\n",
    "        scores.append(int(score))\n",
    "\n",
    "mean, grade = get_threshold(scores)\n",
    "# print(f\"Total={len(PSS)} | Mean={mean} | Lower Thres={grade[0]} | Higher Thres={grade[1]}\")\n",
    "\n",
    "type_count = {0:0, 1:0, 2:0}\n",
    "for name, dict_info in PSS.items():\n",
    "    label = get_stress_type(dict_info['score'], grade)\n",
    "    dict_info['type'] = label\n",
    "    dict_info['type_definition'] = TYPE_DEF[label]\n",
    "    type_count[label] = type_count[label] + 1\n",
    "\n",
    "# print(f\"Non Stress={type_count[0]} | Neutral={type_count[1]} | Stress={type_count[2]}\")\n",
    "\n",
    "# PSS_printer(PSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    PSS = load(\"PSS\")\n",
    "except:\n",
    "    sampling_rate = 125 #Hz\n",
    "    files = glob(f\"data/*.csv\")\n",
    "    for f in tqdm(files):\n",
    "        name = f.split('/')[1].split('__')[0]\n",
    "        pd_raw = pd.read_csv(f, dtype={'Marker':str})\n",
    "        pd_raw = pd_raw.drop(columns='timestamps')\n",
    "        raw = dataframe_to_raw(pd_raw, sfreq=sampling_rate)\n",
    "        PSS[name]['raw'] = raw\n",
    "        # print(f\"{name} | time: {len(pd_raw)/125}\")\n",
    "\n",
    "    save(PSS,\"PSS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8b397962a04f48a01dc0c584d57a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.000 (s)\n",
      "freq=array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
      "       13., 14., 15., 16., 17., 18., 19., 20., 21., 22., 23., 24., 25.,\n",
      "       26., 27., 28., 29., 30., 31., 32., 33., 34., 35., 36., 37., 38.,\n",
      "       39., 40., 41., 42., 43., 44., 45., 46., 47., 48., 49., 50., 51.,\n",
      "       52., 53., 54., 55., 56., 57., 58., 59., 60., 61., 62.])\n",
      "bands=array([array([1, 2, 3]), array([4, 5, 6, 7]), array([ 8,  9, 10, 11, 12]),\n",
      "       array([13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "              30])                                                               ,\n",
      "       array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43]),\n",
      "       array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13]),\n",
      "       array([13, 14, 15, 16, 17])], dtype=object)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27812/3940597707.py:27: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    }
   ],
   "source": [
    "for name, info in tqdm(PSS.items()):\n",
    "    raw = info['raw']\n",
    "    raw.filter(l_freq=1,h_freq=None, method='iir', iir_params={'order':3.0, 'ftype':'butter'}, verbose=False) # Slow drift\n",
    "    raw.notch_filter(freqs=[50])\n",
    "    # epochs = mne.Epochs(raw, np.array([[125*60*1, 0, 1]]), tmin=0, tmax=30, baseline=(0,30), verbose=False)\n",
    "    # print(name)\n",
    "    # a = epochs.plot_psd(picks=['F3','F4','T3','T4'])\n",
    "    # print(\"=\"*40)\n",
    "\n",
    "def get_freq(PSS):\n",
    "    # peak at info\n",
    "    temp = PSS.popitem()\n",
    "    PSS[temp[0]] = temp[1]\n",
    "    raw = temp[1]['raw']\n",
    "    power,freq = mne.time_frequency.psd_welch(raw,n_fft=125, verbose=True)\n",
    "    return freq\n",
    "\n",
    "freq = get_freq(PSS)\n",
    "print(f\"{freq=}\")\n",
    "\n",
    "band_names = np.array(['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma', 'Slow', 'Low_beta'])\n",
    "filter_list = [[1,3],[4,7],[8,12],[13,30],[30,43], [4,13], [13,17]]\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "print(f\"{bands=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = None\n",
    "for name,info in PSS.items():\n",
    "    raw = info['raw']\n",
    "    feature = None\n",
    "    slow, gamma = None, None\n",
    "    a_f3, a_f4 = None, None\n",
    "    a_t7, a_t8 = None, None\n",
    "    b_f3, b_f4 = None, None\n",
    "    b_t7, b_t8 = None, None\n",
    "    \n",
    "    epochs = mne.Epochs(raw, np.array([[125*60*1, 0, 1],[125*60*1.5,0,1]]), tmin=0, tmax=30, baseline=(0,30), verbose=False)\n",
    "    for evoke in epochs.iter_evoked:\n",
    "    for index, band in enumerate(bands):\n",
    "        power,freq = mne.time_frequency.psd_welch(epochs,n_fft=125, verbose=False)\n",
    "        power = power.squeeze()\n",
    "        power = 10 * np.log10(power)\n",
    "        data = power[::,band].mean(axis=1).reshape(1,-1)\n",
    "        # for asym\n",
    "        if(band_names[index] == 'Alpha'):\n",
    "            a_f3 = data[:,raw.ch_names.index('F3')]\n",
    "            a_f4 = data[:,raw.ch_names.index('F4')]\n",
    "            # We use t3 as t7 and t4 as t8\n",
    "            a_t7 = data[:,raw.ch_names.index('T3')]\n",
    "            a_t8 = data[:,raw.ch_names.index('T4')]\n",
    "        if(band_names[index] == 'Beta'):\n",
    "            b_f3 = data[:,raw.ch_names.index('F3')]\n",
    "            b_f4 = data[:,raw.ch_names.index('F4')]\n",
    "            # We use t3 as t7 and t4 as t8\n",
    "            b_t7 = data[:,raw.ch_names.index('T3')]\n",
    "            b_t8 = data[:,raw.ch_names.index('T4')]\n",
    "\n",
    "        ####### Mean for visualization #######\n",
    "        data = data.mean().reshape(1,-1)\n",
    "        # for relative gamma\n",
    "        if(band_names[index] == 'Slow'): slow = data\n",
    "        if(band_names[index] == 'Gamma'): gamma = data\n",
    "\n",
    "        if(type(feature) == type(None)): feature = data\n",
    "        else: feature = np.concatenate([feature, data], axis=1)\n",
    "    # print(feature.shape)\n",
    "    # the eighth feature: relative gamma is slow/gamma\n",
    "    relative_gamma = slow/gamma\n",
    "    feature = np.concatenate([feature, relative_gamma], axis=1)\n",
    "    # The asymetry\n",
    "    alpha_frontal = ((a_f4 - a_f3) / (a_f4 + a_f3)).reshape(1,-1)\n",
    "    feature = np.concatenate([feature, alpha_frontal], axis=1)\n",
    "    # alpha_temporal\n",
    "    alpha_temporal = ((a_t8 - a_t7) / (a_t8 + a_t7)).reshape(1,-1)\n",
    "    feature = np.concatenate([feature, alpha_temporal], axis=1)\n",
    "    # alpha_asymmetry\n",
    "    alpha_asymmetry = alpha_frontal + alpha_temporal\n",
    "    feature = np.concatenate([feature, alpha_asymmetry], axis=1)\n",
    "    # beta_frontal\n",
    "    beta_frontal = ((b_f4 - b_f3) / (b_f4 + b_f3)).reshape(1,-1)\n",
    "    feature = np.concatenate([feature, beta_frontal], axis=1)\n",
    "    # beta_temporal\n",
    "    beta_temporal = ((b_t8 - b_t7) / (b_t8 + b_t7)).reshape(1,-1)\n",
    "    feature = np.concatenate([feature, beta_temporal], axis=1)\n",
    "\n",
    "    # print(slow/gamma)\n",
    "    # print(feature.shape)\n",
    "    # print(feature)\n",
    "    info['feature'] = feature\n",
    "    # if(type(features) == type(None)): features = feature\n",
    "    # else: features = np.concatenate([features, feature], axis=0)\n",
    "# print(features.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(feature)\n",
    "feature_names = list(band_names)\n",
    "feature_names.append('Relative_Gamma')\n",
    "feature_names.append('Alpha_Frontal')\n",
    "feature_names.append('Alpha_Temporal')\n",
    "feature_names.append('Alpha_Asymmetry')\n",
    "feature_names.append('Beta_Frontal')\n",
    "feature_names.append('Beta_Temporal')\n",
    "feature_names = np.array(feature_names)\n",
    "feature_names[[3,10]]\n",
    "X_ori,y_ori = [], []\n",
    "filtered_participants = []\n",
    "filtered_scored = []\n",
    "for index,(name,info) in enumerate(PSS.items()):\n",
    "    # Neutral\n",
    "    if(info['type'] == 1): continue\n",
    "    # Non-Stress\n",
    "    elif(info['type'] == 0):\n",
    "        y_ori.append(0)\n",
    "    # Stress\n",
    "    elif(info['type'] == 2):\n",
    "        y_ori.append(1)\n",
    "    X_ori.append(info['feature'])\n",
    "    filtered_participants.append(name)\n",
    "    filtered_scored.append(info['score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NormJa(data):\n",
    "    for index, row in enumerate(data):\n",
    "        min = row.min()\n",
    "        max = row.max()\n",
    "        mean = row.mean()\n",
    "        row = (row - min) / (max - min)\n",
    "        data[index] = row\n",
    "        # print(row)\n",
    "    return data\n",
    "\n",
    "def StandardJa(data):\n",
    "    data\n",
    "    for index, row in enumerate(data):\n",
    "        mean = row.mean()\n",
    "        std = row.std()\n",
    "        row = (row - mean) / std\n",
    "        data[index] = row\n",
    "        # print(row)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 13) (35,)\n",
      "The best parameters are {'kernel': 'rbf'} with a score of 0.60\n",
      "0.8285714285714286 0.42857142857142855 [0.57142857 0.28571429 0.14285714 0.71428571 0.42857143]\n",
      "[1 0 1 0 0 0 1 1 1 1 0 0 1 0 1 1 1 1 1 0 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.utils import shuffle\n",
    "X,y = np.array(X_ori).squeeze(axis=1), np.array(y_ori)\n",
    "# X = normalize(X.copy(), axis=0)\n",
    "# X = NormJa(X.copy().T).T\n",
    "X = StandardJa(X.copy().T).T\n",
    "X_shuff,y_shuff = shuffle(X,y)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "param_grid = dict(kernel=['linear','poly','rbf', 'sigmoid'])#,'precomputed'])\n",
    "# cv = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "grid = GridSearchCV(SVC(), param_grid=param_grid, cv=5)\n",
    "grid.fit(X, y)\n",
    "print(f\"The best parameters are {grid.best_params_} with a score of {grid.best_score_:.2f}\")\n",
    "\n",
    "model = SVC(kernel='rbf')\n",
    "# model = GaussianNB()\n",
    "model.fit(X_shuff, y_shuff)\n",
    "ans = model.predict(X_shuff)\n",
    "acc = sum(ans == y_shuff) / len(y_shuff)\n",
    "cross = cross_val_score(model, X_shuff, y_shuff, cv=5)\n",
    "print(acc, cross.mean(), cross)\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Non-Stress 16\n",
      "1: Stress 19\n",
      "Wrong\t|pred|label |Score |Name\n",
      "========================================\n",
      "\t|1   |1     |25\t   |fabby\n",
      "\t|1   |1     |25\t   |bas\n",
      "\t|1   |1     |37\t   |flm\n",
      "X\t|1   |0     |12\t   |MJ\n",
      "X\t|0   |1     |28\t   |new\n",
      "\t|0   |0     |15\t   |nuclear\n",
      "\t|1   |1     |29\t   |pang\n",
      "\t|0   |0     |9\t   |prin\n",
      "\t|0   |0     |13\t   |amp\n",
      "\t|0   |0     |9\t   |beau\n",
      "X\t|1   |0     |16\t   |dt\n",
      "\t|0   |0     |15\t   |int\n",
      "\t|1   |1     |24\t   |minkhant\n",
      "\t|1   |1     |27\t   |yong\n",
      "\t|1   |1     |28\t   |aui\n",
      "\t|1   |1     |25\t   |bank\n",
      "\t|1   |1     |24\t   |eiyu\n",
      "\t|0   |0     |13\t   |job\n",
      "\t|1   |1     |25\t   |kee\n",
      "\t|0   |0     |14\t   |miiw\n",
      "\t|0   |0     |8\t   |noey\n",
      "\t|0   |0     |13\t   |shin\n",
      "\t|0   |0     |17\t   |suyo\n",
      "\t|1   |1     |24\t   |yee\n",
      "\t|1   |1     |24\t   |bam\n",
      "X\t|1   |0     |17\t   |beer\n",
      "\t|1   |1     |26\t   |cedric\n",
      "\t|1   |1     |37\t   |fahmai\n",
      "\t|1   |1     |27\t   |gon\n",
      "\t|1   |1     |24\t   |kao\n",
      "X\t|1   |0     |16\t   |mu\n",
      "X\t|1   |0     |11\t   |nisit\n",
      "\t|1   |1     |27\t   |pla\n",
      "\t|1   |1     |27\t   |ploy\n",
      "\t|0   |0     |16\t   |praewphan\n"
     ]
    }
   ],
   "source": [
    "ans = model.predict(X)\n",
    "acc = sum(ans == y) / len(y)\n",
    "print(f\"0: Non-Stress {type_count[0]}\")\n",
    "print(f\"1: Stress {type_count[2]}\")\n",
    "print(f\"Wrong\\t|pred|label |Score |Name\")\n",
    "print(\"=\"*40)\n",
    "for index,(i,j) in enumerate(zip(ans,y)):\n",
    "    wrong = \"\"\n",
    "    if(i != j):\n",
    "        wrong = \"X\"\n",
    "    print(f\"{wrong}\\t|{i}   |{j}     |{filtered_scored[index]}\\t   |{filtered_participants[index]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "815efcf0c7342b169540b615ea1bef3fe0d02f9423b58bdf03d9ef3fd8d24248"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('hci': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
