{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pandas as pd\n",
    "import mne\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(scores):\n",
    "    scores = np.array(scores)\n",
    "    lower_threshold = scores.mean() - (scores.std()/2)\n",
    "    upper_threshold = scores.mean() + (scores.std()/2)\n",
    "    return scores.mean(), (lower_threshold,upper_threshold)\n",
    "\n",
    "def get_stress_type(score, grade):\n",
    "    \"\"\" Non-stress (0): score < lower_threshold\n",
    "        Neutral    (1): lower_threshold <= score <= upper_threshold\n",
    "        Stress     (2): score > lower_threshold \"\"\"\n",
    "    if(score < grade[0]):\n",
    "        return 0\n",
    "    elif(score <= grade[1]):\n",
    "        return 1\n",
    "    elif(score > grade[1]):\n",
    "        return 2\n",
    "\n",
    "def PSS_printer(PSS):\n",
    "    # peak at info\n",
    "    temp = PSS.popitem()\n",
    "    PSS[temp[0]] = temp[1]\n",
    "    column = list(temp[1].keys())\n",
    "    space = \"\\t\\t\"\n",
    "    print(f\"Name{space}\",f\"{space}\".join(column),sep=\"\" )\n",
    "    print(\"=\"*60)\n",
    "    for name, info in PSS.items():\n",
    "        print(f\"{name}{space}\",sep=\"\",end=\"\")\n",
    "        for col in column:\n",
    "            print(f\"{info[col]}{space}\",end=\"\")\n",
    "\n",
    "        print()\n",
    "\n",
    "\n",
    "TYPE_DEF = {0:'Non-Stress', 1:'Neutral', 2: 'Stress'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PSS = dict()\n",
    "scores = []\n",
    "with open('./PSS_scores.csv','r') as f:\n",
    "    f.readline() # skip header\n",
    "    for line in f.readlines(): \n",
    "        name,score = line.split(',')\n",
    "        PSS[name] = {'score':int(score)}\n",
    "        scores.append(int(score))\n",
    "\n",
    "mean, grade = get_threshold(scores)\n",
    "# print(f\"Total={len(PSS)} | Mean={mean} | Lower Thres={grade[0]} | Higher Thres={grade[1]}\")\n",
    "\n",
    "type_count = {0:0, 1:0, 2:0}\n",
    "for name, dict_info in PSS.items():\n",
    "    label = get_stress_type(dict_info['score'], grade)\n",
    "    dict_info['type'] = label\n",
    "    dict_info['type_definition'] = TYPE_DEF[label]\n",
    "    type_count[label] = type_count[label] + 1\n",
    "\n",
    "# print(f\"Non Stress={type_count[0]} | Neutral={type_count[1]} | Stress={type_count[2]}\")\n",
    "\n",
    "# PSS_printer(PSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595b954e9da54694a267c5fd1d8dee2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/56 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sampling_rate = 125 #Hz\n",
    "files = glob(f\"data/*.csv\")\n",
    "for f in tqdm(files):\n",
    "    name = f.split('/')[1].split('__')[0]\n",
    "    pd_raw = pd.read_csv(f, dtype={'Marker':str})\n",
    "    pd_raw = pd_raw.drop(columns='timestamps')\n",
    "    raw = dataframe_to_raw(pd_raw, sfreq=sampling_rate)\n",
    "    PSS[name]['raw'] = raw\n",
    "    # print(f\"{name} | time: {len(pd_raw)/125}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save(PSS,\"PSS\")\n",
    "\n",
    "PSS = load(\"PSS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65bd3d0c02c14acb95cd9bfbb3938975",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, info in tqdm(PSS.items()):\n",
    "    raw = info['raw']\n",
    "    raw.filter(l_freq=1,h_freq=None, method='iir', iir_params={'order':3.0, 'ftype':'butter'}, verbose=False) # Slow drift\n",
    "    raw.notch_filter(freqs=[50])\n",
    "    # epochs = mne.Epochs(raw, np.array([[125*60*1, 0, 1]]), tmin=0, tmax=30, baseline=(0,30), verbose=False)\n",
    "    # print(name)\n",
    "    # a = epochs.plot_psd(picks=['F3','F4','T3','T4'])\n",
    "    # print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.000 (s)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53.\n",
      " 54. 55. 56. 57. 58. 59. 60. 61. 62.]\n"
     ]
    }
   ],
   "source": [
    "def get_freq(PSS):\n",
    "    # peak at info\n",
    "    temp = PSS.popitem()\n",
    "    PSS[temp[0]] = temp[1]\n",
    "    raw = temp[1]['raw']\n",
    "    power,freq = mne.time_frequency.psd_welch(raw,n_fft=125, verbose=True)\n",
    "    return freq\n",
    "\n",
    "freq = get_freq(PSS)\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([1, 2, 3]) array([4, 5, 6, 7]) array([ 8,  9, 10, 11, 12])\n",
      " array([13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30])\n",
      " array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43])\n",
      " array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13])\n",
      " array([13, 14, 15, 16, 17])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8637/3256231302.py:7: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    }
   ],
   "source": [
    "band_names = np.array(['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma', 'Slow', 'Low_beta'])\n",
    "filter_list = [[1,3],[4,7],[8,12],[13,30],[30,43], [4,13], [13,17]]\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "print(bands)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv.shape=(1, 117)\n",
      "csv.shape=(2, 117)\n",
      "csv.shape=(3, 117)\n",
      "csv.shape=(4, 117)\n",
      "csv.shape=(5, 117)\n",
      "csv.shape=(6, 117)\n",
      "csv.shape=(7, 117)\n",
      "csv.shape=(8, 117)\n",
      "csv.shape=(9, 117)\n",
      "csv.shape=(10, 117)\n",
      "csv.shape=(11, 117)\n",
      "csv.shape=(12, 117)\n",
      "csv.shape=(13, 117)\n",
      "csv.shape=(14, 117)\n",
      "csv.shape=(15, 117)\n",
      "csv.shape=(16, 117)\n",
      "csv.shape=(17, 117)\n",
      "csv.shape=(18, 117)\n",
      "csv.shape=(19, 117)\n",
      "csv.shape=(20, 117)\n",
      "csv.shape=(21, 117)\n",
      "csv.shape=(22, 117)\n",
      "csv.shape=(23, 117)\n",
      "csv.shape=(24, 117)\n",
      "csv.shape=(25, 117)\n",
      "csv.shape=(26, 117)\n",
      "csv.shape=(27, 117)\n",
      "csv.shape=(28, 117)\n",
      "csv.shape=(29, 117)\n",
      "csv.shape=(30, 117)\n",
      "csv.shape=(31, 117)\n",
      "csv.shape=(32, 117)\n",
      "csv.shape=(33, 117)\n",
      "csv.shape=(34, 117)\n",
      "csv.shape=(35, 117)\n",
      "csv.shape=(36, 117)\n",
      "csv.shape=(37, 117)\n",
      "csv.shape=(38, 117)\n",
      "csv.shape=(39, 117)\n",
      "csv.shape=(40, 117)\n",
      "csv.shape=(41, 117)\n",
      "csv.shape=(42, 117)\n",
      "csv.shape=(43, 117)\n",
      "csv.shape=(44, 117)\n",
      "csv.shape=(45, 117)\n",
      "csv.shape=(46, 117)\n",
      "csv.shape=(47, 117)\n",
      "csv.shape=(48, 117)\n",
      "csv.shape=(49, 117)\n",
      "csv.shape=(50, 117)\n",
      "csv.shape=(51, 117)\n",
      "csv.shape=(52, 117)\n",
      "csv.shape=(53, 117)\n",
      "csv.shape=(54, 117)\n",
      "csv.shape=(55, 117)\n"
     ]
    }
   ],
   "source": [
    "# features = None\n",
    "csv = None\n",
    "names = []\n",
    "for name,info in PSS.items():\n",
    "    names.append(name)\n",
    "    raw = info['raw']\n",
    "    row = None\n",
    "    feature = None\n",
    "    slow, gamma = None, None\n",
    "    a_f3, a_f4 = None, None\n",
    "    a_t7, a_t8 = None, None\n",
    "    b_f3, b_f4 = None, None\n",
    "    b_t7, b_t8 = None, None\n",
    "    # epochs = mne.Epochs(raw, np.array([[125*60*1, 0, 1]]), tmin=0, tmax=30, baseline=(0,30), verbose=False)\n",
    "    for index, band in enumerate(bands):\n",
    "        power,freq = mne.time_frequency.psd_welch(raw,n_fft=125, verbose=False)\n",
    "        power = power.squeeze()\n",
    "        power = 10 * np.log10(power)\n",
    "        data = power[::,band].mean(axis=1).reshape(1,-1)\n",
    "        # print(f\"{data.shape=}\")\n",
    "\n",
    "        if(type(row) == type(None)): row = data.copy()\n",
    "        else: row = np.concatenate([row,data.copy()], axis=1)\n",
    "\n",
    "        # print(f\"{row.shape=}\")\n",
    "        # for asym\n",
    "        if(band_names[index] == 'Alpha'):\n",
    "            a_f3 = data[:,raw.ch_names.index('F3')]\n",
    "            a_f4 = data[:,raw.ch_names.index('F4')]\n",
    "            # We use t3 as t7 and t4 as t8\n",
    "            a_t7 = data[:,raw.ch_names.index('T3')]\n",
    "            a_t8 = data[:,raw.ch_names.index('T4')]\n",
    "        if(band_names[index] == 'Beta'):\n",
    "            b_f3 = data[:,raw.ch_names.index('F3')]\n",
    "            b_f4 = data[:,raw.ch_names.index('F4')]\n",
    "            # We use t3 as t7 and t4 as t8\n",
    "            b_t7 = data[:,raw.ch_names.index('T3')]\n",
    "            b_t8 = data[:,raw.ch_names.index('T4')]\n",
    "\n",
    "        ####### Mean for visualization #######\n",
    "        data = data.mean().reshape(1,-1)\n",
    "        # for relative gamma\n",
    "        if(band_names[index] == 'Slow'): slow = data\n",
    "        if(band_names[index] == 'Gamma'): gamma = data\n",
    "\n",
    "        if(type(feature) == type(None)): feature = data\n",
    "        else: feature = np.concatenate([feature, data], axis=1)\n",
    "    # print(feature.shape)\n",
    "    # the eighth feature: relative gamma is slow/gamma\n",
    "    relative_gamma = slow/gamma\n",
    "    feature = np.concatenate([feature, relative_gamma], axis=1)\n",
    "    # The asymetry\n",
    "    alpha_frontal = ((a_f4 - a_f3) / (a_f4 + a_f3)).reshape(1,-1)\n",
    "    feature = np.concatenate([feature, alpha_frontal], axis=1)\n",
    "    # alpha_temporal\n",
    "    alpha_temporal = ((a_t8 - a_t7) / (a_t8 + a_t7)).reshape(1,-1)\n",
    "    feature = np.concatenate([feature, alpha_temporal], axis=1)\n",
    "    # alpha_asymmetry\n",
    "    alpha_asymmetry = alpha_frontal + alpha_temporal\n",
    "    feature = np.concatenate([feature, alpha_asymmetry], axis=1)\n",
    "    # beta_frontal\n",
    "    beta_frontal = ((b_f4 - b_f3) / (b_f4 + b_f3)).reshape(1,-1)\n",
    "    feature = np.concatenate([feature, beta_frontal], axis=1)\n",
    "    # beta_temporal\n",
    "    beta_temporal = ((b_t8 - b_t7) / (b_t8 + b_t7)).reshape(1,-1)\n",
    "    feature = np.concatenate([feature, beta_temporal], axis=1)\n",
    "\n",
    "    row = np.concatenate([row, relative_gamma, alpha_frontal, alpha_asymmetry, beta_frontal, beta_temporal], axis=1)\n",
    "    # print(slow/gamma)\n",
    "    # print(feature.shape)\n",
    "    # print(feature)\n",
    "    info['feature'] = feature\n",
    "    if(type(csv) == type(None)): csv = row\n",
    "    else: csv = np.concatenate([csv,row], axis=0)\n",
    "    print(f\"{csv.shape=}\")\n",
    "    # break\n",
    "    # if(type(features) == type(None)): features = feature\n",
    "    # else: features = np.concatenate([features, feature], axis=0)\n",
    "# print(features.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"feature.csv\",\"w\") as f:\n",
    "    # print(raw.ch_names[:-1])\n",
    "    # print(band_names)\n",
    "    header = [\"name\"]\n",
    "    for band_name in band_names:\n",
    "        for ch_name in raw.ch_names[:-1]:\n",
    "            header.append(f\"{ch_name}_{band_name}\")\n",
    "    f.write(\",\".join(header))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"foo.csv\", csv, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fabby', 'bas', 'flm', 'mind', 'taew', 'MJ', 'nopphon', 'boss', 'film', 'new', 'nice', 'nuclear', 'pang', 'prin', 'amp', 'beau', 'dt', 'int', 'minkhant', 'sam', 'yong', 'aui', 'bank', 'dream', 'eiyu', 'ice', 'job', 'kee', 'miiw', 'noey', 'pear', 'por', 'satya', 'shin', 'suyo', 'tom', 'yee', 'aun', 'bam', 'beer', 'cedric', 'fahmai', 'gon', 'harold', 'kant', 'kao', 'mu', 'nisit', 'pla', 'ploy', 'poon', 'praewphan', 's', 'younten', 'tor']\n"
     ]
    }
   ],
   "source": [
    "print(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7654832a5c07ba51f6a7dd359878d2f06413119b7bd7e7ad6b152fbeef99d7e"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('EEG_ChronicStress-9HAbJ5VQ': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
