{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pandas as pd\n",
    "import mne\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.preprocessing import normalize, StandardScaler\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "TYPE_DEF = {0:'Non-Stress', 1:'Neutral', 2: 'Stress'}\n",
    "PSS = load('PSS')\n",
    "type_count = load('type_count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Effective window size : 1.000 (s)\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  7.  8.  9. 10. 11. 12. 13. 14. 15. 16. 17.\n",
      " 18. 19. 20. 21. 22. 23. 24. 25. 26. 27. 28. 29. 30. 31. 32. 33. 34. 35.\n",
      " 36. 37. 38. 39. 40. 41. 42. 43. 44. 45. 46. 47. 48. 49. 50. 51. 52. 53.\n",
      " 54. 55. 56. 57. 58. 59. 60. 61. 62.]\n",
      "[array([1, 2, 3]) array([4, 5, 6, 7]) array([ 8,  9, 10, 11, 12])\n",
      " array([13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29,\n",
      "        30])\n",
      " array([30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43])\n",
      " array([ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13])\n",
      " array([13, 14, 15, 16, 17])]\n",
      "step_minutes=array([0.  , 0.25, 0.5 , 0.75, 1.  , 1.25, 1.5 , 1.75, 2.  , 2.25, 2.5 ,\n",
      "       2.75, 3.  , 3.25, 3.5 , 3.75, 4.  , 4.25, 4.5 , 4.75])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_15770/3477651712.py:25: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  bands = np.array(bands)\n"
     ]
    }
   ],
   "source": [
    "def get_freq(PSS):\n",
    "    # peak at info\n",
    "    temp = PSS.popitem()\n",
    "    PSS[temp[0]] = temp[1]\n",
    "    raw = temp[1]['raw']\n",
    "    power,freq = mne.time_frequency.psd_welch(raw,n_fft=125, verbose=True)\n",
    "    return freq\n",
    "\n",
    "\n",
    "for name, info in PSS.items():\n",
    "    raw = info['raw']\n",
    "    # raw.filter(l_freq=1,h_freq=None, method='iir', iir_params={'order':3.0, 'ftype':'butter'}, verbose=False) # Slow drift\n",
    "    # raw.notch_filter(freqs=[50])\n",
    "\n",
    "freq = get_freq(PSS)\n",
    "print(freq)\n",
    "\n",
    "\n",
    "band_names = np.array(['Delta', 'Theta', 'Alpha', 'Beta', 'Gamma', 'Slow', 'Low_beta'])\n",
    "filter_list = [[1,3],[4,7],[8,12],[13,30],[30,43], [4,13], [13,17]]\n",
    "bands = []\n",
    "for filt in filter_list:\n",
    "    pt = np.argwhere((freq >= filt[0]) & (freq <= filt[1])).reshape(-1)\n",
    "    bands.append(pt)\n",
    "bands = np.array(bands)\n",
    "print(bands)\n",
    "\n",
    "def get_markers():\n",
    "    sampling_rate = 125 #Hz\n",
    "    # 15/60 = 0.25\n",
    "    step_minutes = np.arange(0,5,0.25)\n",
    "    print(f\"{step_minutes=}\")\n",
    "    step_minutes = np.expand_dims(step_minutes * sampling_rate * 60, axis=1)\n",
    "    markers = np.concatenate( [step_minutes, np.zeros( step_minutes.shape ), np.ones( step_minutes.shape ) ], axis=1  ).astype(np.int64)\n",
    "    return markers\n",
    "markers = get_markers()\n",
    "# markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feature_epochs.shape=(20, 133)\n"
     ]
    }
   ],
   "source": [
    "for name,info in PSS.items():\n",
    "    raw = info['raw']\n",
    "    epochs = mne.Epochs(raw, markers, tmin=0, tmax=15, baseline=(0,2), verbose=False)\n",
    "    feature_epochs = None\n",
    "    for evoked in epochs.iter_evoked():\n",
    "        feature = None\n",
    "        slow, gamma = None, None\n",
    "        a_f3, a_f4 = None, None\n",
    "        a_t7, a_t8 = None, None\n",
    "        b_f3, b_f4 = None, None\n",
    "        b_t7, b_t8 = None, None\n",
    "        for index, band in enumerate(bands):\n",
    "            power,freq = mne.time_frequency.psd_welch(evoked,n_fft=125, verbose=False)\n",
    "            power = power.squeeze()\n",
    "            power = 10 * np.log10(power)\n",
    "            data = power[::,band].mean(axis=1).reshape(1,-1)\n",
    "            # for asym\n",
    "            if(band_names[index] == 'Alpha'):\n",
    "                a_f3 = data[:,raw.ch_names.index('F3')]\n",
    "                a_f4 = data[:,raw.ch_names.index('F4')]\n",
    "                # We use t3 as t7 and t4 as t8\n",
    "                a_t7 = data[:,raw.ch_names.index('T3')]\n",
    "                a_t8 = data[:,raw.ch_names.index('T4')]\n",
    "            if(band_names[index] == 'Beta'):\n",
    "                b_f3 = data[:,raw.ch_names.index('F3')]\n",
    "                b_f4 = data[:,raw.ch_names.index('F4')]\n",
    "                # We use t3 as t7 and t4 as t8\n",
    "                b_t7 = data[:,raw.ch_names.index('T3')]\n",
    "                b_t8 = data[:,raw.ch_names.index('T4')]\n",
    "\n",
    "            ####### Mean for visualization #######\n",
    "            data = data.reshape(1,-1)\n",
    "            # print(data.shape)\n",
    "            # for relative gamma\n",
    "            if(band_names[index] == 'Slow'): slow = data\n",
    "            if(band_names[index] == 'Gamma'): gamma = data\n",
    "\n",
    "            if(type(feature) == type(None)): feature = data\n",
    "            else: feature = np.concatenate([feature, data], axis=1)\n",
    "        # print(feature.shape)\n",
    "        # the eighth feature: relative gamma is slow/gamma\n",
    "        relative_gamma = slow/gamma\n",
    "        feature = np.concatenate([feature, relative_gamma], axis=1)\n",
    "        # The asymetry\n",
    "        alpha_frontal = ((a_f4 - a_f3) / (a_f4 + a_f3)).reshape(1,-1)\n",
    "        feature = np.concatenate([feature, alpha_frontal], axis=1)\n",
    "        # alpha_temporal\n",
    "        alpha_temporal = ((a_t8 - a_t7) / (a_t8 + a_t7)).reshape(1,-1)\n",
    "        feature = np.concatenate([feature, alpha_temporal], axis=1)\n",
    "        # alpha_asymmetry\n",
    "        alpha_asymmetry = alpha_frontal + alpha_temporal\n",
    "        feature = np.concatenate([feature, alpha_asymmetry], axis=1)\n",
    "        # beta_frontal\n",
    "        beta_frontal = ((b_f4 - b_f3) / (b_f4 + b_f3)).reshape(1,-1)\n",
    "        feature = np.concatenate([feature, beta_frontal], axis=1)\n",
    "        # beta_temporal\n",
    "        beta_temporal = ((b_t8 - b_t7) / (b_t8 + b_t7)).reshape(1,-1)\n",
    "        feature = np.concatenate([feature, beta_temporal], axis=1)\n",
    "        if(type(feature_epochs) == type(None)): feature_epochs = feature\n",
    "        else: feature_epochs = np.concatenate( [feature_epochs, feature], axis=0 )\n",
    "    info['feature'] = feature_epochs\n",
    "print(f\"{feature_epochs.shape=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136 133 (20, 133)\n"
     ]
    }
   ],
   "source": [
    "feature_names = []\n",
    "for band_name in band_names:\n",
    "    for ch_name in raw.ch_names[:-1]:\n",
    "        feature_names.append(f\"{ch_name}_{band_name}\")\n",
    "for ch_name in raw.ch_names[:-1]:\n",
    "    feature_names.append(f\"{ch_name}_relative_gamma\")\n",
    "feature_names.append(\"alpha_frontal\")\n",
    "feature_names.append(\"alpha_temporal\")\n",
    "feature_names.append(\"alpha_asymmetry\")\n",
    "feature_names.append(\"beta_frontal\")\n",
    "feature_names.append(\"beta_temporal\")\n",
    "\n",
    "headers = [\"name\",\"types\",\"scores\"] + feature_names\n",
    "print(len(headers), len(feature_names), feature_epochs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_stress_count=320 stress_count=400\n",
      "np.array(X_ori).shape=(1100, 133)\n",
      "len(participants)=1100\n",
      "len(scores)=1100\n",
      "len(types)=1100\n"
     ]
    }
   ],
   "source": [
    "X_ori,y_ori = [], []\n",
    "participants = []\n",
    "scores = []\n",
    "types = []\n",
    "non_stress_count, stress_count = 0,0\n",
    "for index,(name,info) in enumerate(PSS.items()):\n",
    "    for feature in info['feature']:\n",
    "        # Neutral\n",
    "        # if(info['type'] == 1): continue\n",
    "        # if(info['type'] == 1): continue\n",
    "        # Non-Stress\n",
    "        if(info['type'] == 0):\n",
    "            non_stress_count = non_stress_count + 1\n",
    "        #     # print(name, info['score'])\n",
    "        #     y_ori.append(0)\n",
    "        # Stress\n",
    "        elif(info['type'] == 2):\n",
    "            stress_count = stress_count + 1\n",
    "        #     y_ori.append(1)\n",
    "        X_ori.append(feature)\n",
    "        participants.append(name)\n",
    "        scores.append(info['score'])\n",
    "        types.append(info['type'])\n",
    "print(f\"{non_stress_count=} {stress_count=}\")\n",
    "print(f\"{np.array(X_ori).shape=}\")\n",
    "print(f\"{len(participants)=}\")\n",
    "print(f\"{len(scores)=}\")\n",
    "print(f\"{len(types)=}\")\n",
    "# print(f\"{np.array(y_ori).shape=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'name':participants,\n",
    "        'score':scores,\n",
    "        'type':types}\n",
    "for col,feature_name in zip(np.array(X_ori).T,feature_names):\n",
    "    # print(feature_name,col.shape)\n",
    "    data[feature_name] = list(col)\n",
    "\n",
    "csv = pd.DataFrame(data)\n",
    "csv.to_csv('export/15s_133features_all_baseline.csv')\n",
    "csv[csv['type']!=1].to_csv('export/15s_133features_filter_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_float(data):\n",
    "    if(data.dtype == np.int64): data = data.astype(np.float64)\n",
    "    return data\n",
    "\n",
    "def StandardJa(data):\n",
    "    data = check_float(data)\n",
    "    for index, row in enumerate(data):\n",
    "        mean = row.mean()\n",
    "        std = row.std()\n",
    "        row = (row - mean) / std\n",
    "        data[index] = row\n",
    "        # print(row)\n",
    "    return data\n",
    "\n",
    "X_ori_std = StandardJa(np.array(X_ori).copy().T).T\n",
    "\n",
    "data = {'name':participants,\n",
    "        'score':scores,\n",
    "        'type':types}\n",
    "for col,feature_name in zip(X_ori_std.T,feature_names):\n",
    "    # print(feature_name,col.shape)\n",
    "    data[feature_name] = list(col)\n",
    "\n",
    "csv = pd.DataFrame(data)\n",
    "csv.to_csv('export/15s_133features_all_std_baseline.csv')\n",
    "csv[csv['type']!=1].to_csv('export/15s_133features_filter_std_baseline.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0eebe16e4c52cb0ff0c850947dc1c747e982716f4a14d440d1344740168caad5"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': pipenv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
